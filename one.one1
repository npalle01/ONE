#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
BRM MASTER CODE (Consolidated + Enhanced)
Part 1/?

This integrated code merges:
 • Original foundation (Parts 1–8)
 • Advanced Search & Filtering (multi-criteria, saved filters, suggestions)
 • Intelligent Rule Editing & SQL Assistance (SQL validation, warnings, templates)
 • Enhanced Onboarding & In-App Guidance
 • Threaded Collaboration & Mentions
 • Extended Hierarchy & Lineage Graph Interactions
 • "What-If" Testing with interactive test data editor
 • Multi-step approvals with richer pipeline visualization & parallel options
 • Task & Notification Center
 • Richer Conflict Resolution Tools (visual map)
 • Enhanced Snapshots & Version Diff
 • Usage Analytics & Heatmaps
 • AIOps (Anomaly detection & auto-escalation)
 • Configurable Roles & Permissions (RBAC/ABAC approach)
 • Visually Rich Approval Pipeline
Plus the entire original code for DB connection, logging, BFS execution, synchronization, etc.

NOTE:
 - This is a “best-effort” integrated code. It may not match your original line numbering or exact text from the prior 6000+ lines. 
 - It includes placeholders or partial logic for advanced features (like advanced RBAC) that would require additional DB schema & logic.

Contents:
  (1) Imports & Logging Config
  (2) DB Connection Dialog
  (3) Basic & Advanced DB Helpers
  (4) EmailNotifier & Collaboration
  (5) LockManager (unified approach)
  (6) Advanced SQL Parser
  (7) Login Dialog
  (8) Onboarding Wizard
  (9) sync_metadata_improved
  (10) BFS Rule Execution & Data Validations
  (11) Decision Table Execution
  (12) Dry-run Simulations
  (13) GUI Modules:
      • EnhancedScheduleDialog, ScheduleManagementTab
      • ChainSimulationDialog, GroupSimulationDialog
      • DecisionTablesTab, ConflictPriorityManagerTab
      • CompositeRulesTab, SnapshotManagerTab, TagsManagerTab
      • DataValidationTab, WhatIfTestTab
  (14) Collaboration, Custom Groups, Extended Hierarchy
  (15) MultiStepApprovalTab (extended pipeline UI)
  (16) GlobalCriticalAdminTab
  (17) EnhancedLineageGraphWidget
  (18) MetricsDashboardTab with Heatmaps
  (19) CtrlTablesTab, GroupManagementTab, UserManagementTab
  (20) Advanced RBAC/ABAC placeholders
  (21) BusinessRulesTab (with advanced search & filtering)
  (22) ApprovalsTab (with comments & partial or parallel approvals)
  (23) SchedulingTab
  (24) DefectManagementTab
  (25) CollaborationTab (threaded + mention)
  (26) AuditLogViewer with advanced search & CSV/JSON/Excel export
  (27) RuleSearchDialog
  (28) VersionHistoryDialog with diff
  (29) RuleDashboard
  (30) RuleEditorDialog (with SQL assistance, template library)
  (31) Additional advanced features (Richer conflict resolution map, anomaly detection, auto-healing, etc.)
  (32) MainWindow Integration + Task/Notification Center
  (33) HelpFeedbackTab, advanced Onboarding integration
  (34) main() function with everything tied together
"""

import sys
import os
import json
import math
import csv
import re
import logging
import logging.config
import difflib
import random
from datetime import datetime, timedelta
from collections import defaultdict, deque
from sklearn.linear_model import LinearRegression  # for simple anomaly/trend detection

# PyQt5 imports
from PyQt5 import QtCore, QtGui, QtWidgets
from PyQt5.QtCore import Qt, QDateTime, QTimer, QDate, QTime, QPointF, pyqtSignal
from PyQt5.QtGui import QFont, QColor, QPen, QBrush, QIcon
from PyQt5.QtWidgets import (
    QDialog, QVBoxLayout, QLabel, QLineEdit, QPushButton, QHBoxLayout, 
    QMessageBox, QComboBox, QPlainTextEdit, QCalendarWidget, QTimeEdit, 
    QFormLayout, QWidget, QCheckBox, QTableWidget, QTableWidgetItem,
    QInputDialog, QMenu, QListWidget, QListWidgetItem, QTreeWidget,
    QTreeWidgetItem, QDockWidget, QMainWindow, QTabWidget, QGroupBox,
    QSpinBox, QProgressDialog, QSplitter, QFileDialog
)

import smtplib
from email.mime.text import MIMEText

import pyodbc
import sqlparse
import pyqtgraph as pg

##############################################################################
# (1) LOGGING CONFIG & GLOBAL SETTINGS
##############################################################################

# Enhanced Logging Configuration (can be moved to a separate file if needed)
LOG_CONFIG = {
    "version": 1,
    "disable_existing_loggers": False,
    "formatters": {
        "standard": {
            "format": "%(asctime)s [%(levelname)s] %(name)s: %(message)s"
        }
    },
    "handlers": {
        "console": {
            "class": "logging.StreamHandler",
            "formatter": "standard",
            "level": "DEBUG"
        },
        "file": {
            "class": "logging.FileHandler",
            "filename": os.getenv("BRM_LOG_FILE", "brm_core.log"),
            "formatter": "standard",
            "level": os.getenv("BRM_LOG_LEVEL", "INFO")
        }
    },
    "root": {
        "handlers": ["console", "file"],
        "level": "DEBUG"
    }
}

logging.config.dictConfig(LOG_CONFIG)
logger = logging.getLogger("brm_master")

##############################################################################
# (2) DATABASE CONNECTION DIALOG
##############################################################################

class DatabaseConnectionDialog(QtWidgets.QDialog):
    """
    A dialog to select or enter an ODBC DSN / connection string.
    Enhanced to handle test-connection logic, error display, etc.
    """
    def __init__(self, parent=None):
        super().__init__(parent)
        self.connection = None
        self.setWindowTitle("DB Connection – Enhanced")
        self.resize(400, 200)

        main_layout = QVBoxLayout(self)
        lbl = QLabel("Select ODBC DSN or provide a custom connection string:")
        main_layout.addWidget(lbl)

        self.dsn_combo = QComboBox()
        try:
            dsn_dict = pyodbc.dataSources()
            # Filter DSNs that appear to be SQL Server or similar
            for dsn_name, driver in dsn_dict.items():
                if "SQL" in driver.upper() or "ODBC" in driver.upper():
                    self.dsn_combo.addItem(f"ODBC DSN: {dsn_name}", dsn_name)
        except Exception as ex:
            logger.error(f"Error listing DSNs: {ex}")
        main_layout.addWidget(self.dsn_combo)

        self.conn_str_edit = QLineEdit()
        self.conn_str_edit.setPlaceholderText("Or enter custom ODBC connection string (optional)")
        main_layout.addWidget(self.conn_str_edit)

        btn_h = QHBoxLayout()
        ok_btn = QPushButton("Connect")
        ok_btn.clicked.connect(self.accept)
        cancel_btn = QPushButton("Cancel")
        cancel_btn.clicked.connect(self.reject)
        btn_h.addWidget(ok_btn)
        btn_h.addWidget(cancel_btn)
        main_layout.addLayout(btn_h)

    def get_connection(self):
        """
        Attempts to create a pyodbc connection with user’s chosen DSN or custom string.
        Returns None if it fails.
        """
        custom_str = self.conn_str_edit.text().strip()
        if custom_str:
            conn_str = custom_str
        else:
            sel = self.dsn_combo.currentData()
            if not sel:
                QMessageBox.critical(self, "Error", "No DSN or custom connection string provided.")
                return None
            conn_str = f"DSN={sel};Trusted_Connection=yes;"
        try:
            conn = pyodbc.connect(conn_str)
            logger.info("Database connection established successfully.")
            return conn
        except Exception as ex:
            QMessageBox.critical(self, "Connection Error", str(ex))
            logger.error(f"DB connection failed: {ex}")
            return None

    def accept(self):
        test_conn = self.get_connection()
        if test_conn:
            self.connection = test_conn
            super().accept()
        else:
            # Remain in the dialog for user correction
            pass

##############################################################################
# (3) BASIC & ADVANCED DB HELPERS
##############################################################################

def fetch_all_dict(cursor):
    """
    Fetch all rows into a list of dicts if description is present, else raw rows.
    """
    rows = cursor.fetchall()
    if cursor.description:
        colnames = [d[0] for d in cursor.description]
        out = []
        for r_ in rows:
            out.append(dict(zip(colnames, r_)))
        return out
    else:
        return rows

def fetch_one_dict(cursor):
    """
    Fetch the next row as dict (if present) or None.
    """
    row = cursor.fetchone()
    if row and cursor.description:
        colnames = [d[0] for d in cursor.description]
        return dict(zip(colnames, row))
    return None

def insert_audit_log(conn, action, table_name, record_id, actor, old_data=None, new_data=None):
    """
    Insert an audit record into BRM_AUDIT_LOG with optional old/new data as JSON.
    Enhanced: Incorporates robust error handling.
    """
    try:
        c = conn.cursor()
        c.execute("""
            INSERT INTO BRM_AUDIT_LOG(
                ACTION, TABLE_NAME, RECORD_ID, ACTION_BY,
                OLD_DATA, NEW_DATA, ACTION_TIMESTAMP
            )
            VALUES(?,?,?,?,?,?,GETDATE())
        """, (
            action, table_name,
            str(record_id) if record_id else None,
            actor,
            json.dumps(old_data) if old_data else None,
            json.dumps(new_data) if new_data else None
        ))
        conn.commit()
        logger.debug(f"Audit log inserted => action={action}, table={table_name}, record_id={record_id}, actor={actor}")
    except Exception as ex:
        logger.error(f"Error inserting audit log: {ex}")

def create_multistep_approvals(conn, rule_id, initiated_by):
    """
    Creates multi-step approval process records for a rule in BRM_RULE_APPROVALS.
    Enhanced with possibility for parallel or staged approvals in an advanced scenario.

    In a real scenario, the logic might read from a config table to see which groups must 
    approve a rule referencing certain tables or with a certain critical scope. 
    This code is a simplified example with 2 sequential steps.
    """
    try:
        c = conn.cursor()
        # Example: 2-stage, first "OwnerGroup" then "GlobalApprovers"
        # Could also handle parallel steps if needed.
        # For advanced parallel logic, we'd set something like APPROVAL_STAGE=1 for multiple rows, 
        # and the rule moves to next stage only if all parallel stage=1 approvals are done, etc.
        c.execute("SELECT OWNER_GROUP, CRITICAL_SCOPE FROM BRM_RULES WHERE RULE_ID=?", (rule_id,))
        row = c.fetchone()
        if not row:
            raise ValueError("Rule not found for approvals")
        owner_group, crit_scope = row
        # Insert stage 1
        c.execute("""
            INSERT INTO BRM_RULE_APPROVALS(RULE_ID, GROUP_NAME, USERNAME, APPROVED_FLAG, APPROVAL_STAGE, APPROVAL_TYPE)
            VALUES(?, ?, ?, 0, 1, 'SERIAL')
        """, (rule_id, owner_group, initiated_by))
        # Insert stage 2 (global or final approver):
        c.execute("""
            INSERT INTO BRM_RULE_APPROVALS(RULE_ID, GROUP_NAME, USERNAME, APPROVED_FLAG, APPROVAL_STAGE, APPROVAL_TYPE)
            VALUES(?, ?, ?, 0, 2, 'SERIAL')
        """, (rule_id, "GlobalApprovers", initiated_by))
        conn.commit()
        logger.info(f"Multi‑step approvals created for rule {rule_id} by {initiated_by}")
    except Exception as ex:
        conn.rollback()
        logger.error(f"Error creating multi‑step approvals for rule {rule_id}: {ex}")
        raise

##############################################################################
# (4) EMAIL NOTIFIER & COLLABORATION
##############################################################################

class EmailNotifier:
    """
    Sends emails via SMTP, reading credentials from environment variables
    or falling back to placeholder defaults.
    Provides detailed logging and error reporting.
    """
    def __init__(self):
        self.smtp_server = os.getenv("BRM_SMTP_SERVER", "smtp.example.com")
        self.smtp_port = int(os.getenv("BRM_SMTP_PORT", 587))
        self.smtp_username = os.getenv("BRM_SMTP_USERNAME", "your_smtp_user")
        self.smtp_password = os.getenv("BRM_SMTP_PASSWORD", "your_smtp_pass")
        self.sender_email = os.getenv("BRM_SENDER_EMAIL", "noreply@example.com")

    def send_email(self, subject: str, body: str, recipients: list):
        if not recipients:
            logger.warning("No recipients provided for email.")
            return
        try:
            msg = MIMEText(body, 'plain')
            msg['Subject'] = subject
            msg['From'] = self.sender_email
            msg['To'] = ", ".join(recipients)

            smtp = smtplib.SMTP(self.smtp_server, self.smtp_port)
            smtp.starttls()
            smtp.login(self.smtp_username, self.smtp_password)
            smtp.sendmail(self.sender_email, recipients, msg.as_string())
            smtp.quit()
            logger.info(f"Email sent to {recipients}")
        except Exception as e:
            logger.error(f"Error sending email to {recipients}: {e}")
            raise

class CollaborationManager(QtCore.QObject):
    """
    Periodically polls a COLLABORATION_LOGS table to retrieve new messages.
    Enhanced for potential multi-thread or mention logic in future expansions.
    """
    newMessage = QtCore.pyqtSignal(dict)

    def __init__(self, connection, poll_ms=5000, parent=None):
        super().__init__(parent)
        self.connection = connection
        self.poll_ms = poll_ms
        self.timer = QTimer(self)
        self.timer.timeout.connect(self.poll_messages)
        self.last_timestamp = None
        self.timer.start(self.poll_ms)

    def poll_messages(self):
        c = self.connection.cursor()
        try:
            if self.last_timestamp:
                c.execute("""
                    SELECT MESSAGE, SENDER, TIMESTAMP 
                    FROM COLLABORATION_LOGS 
                    WHERE TIMESTAMP > ? 
                    ORDER BY TIMESTAMP ASC
                """, (self.last_timestamp,))
            else:
                c.execute("SELECT MESSAGE, SENDER, TIMESTAMP FROM COLLABORATION_LOGS ORDER BY TIMESTAMP ASC")
            rows = c.fetchall()
            if rows:
                for row in rows:
                    message, sender, ts = row
                    self.newMessage.emit({"message": message, "sender": sender, "timestamp": ts})
                    self.last_timestamp = ts
        except Exception as ex:
            logger.error(f"Error polling collaboration messages: {ex}")

##############################################################################
# (5) LOCK MANAGER (UNIFIED APPROACH)
##############################################################################

class LockManager:
    """
    Stores locks in BRM_RULE_LOCKS with expiry.
    Provides:
      • auto_unlock_expired_locks
      • rule_current_lock_owner
      • lock_rule_for_edit
      • unlock_rule_for_edit
    Enhanced with more robust error handling and logging.
    """

    @staticmethod
    def auto_unlock_expired_locks(conn):
        now = datetime.now()
        c = conn.cursor()
        try:
            c.execute("""
                UPDATE BRM_RULE_LOCKS
                SET ACTIVE_LOCK=0
                WHERE ACTIVE_LOCK=1
                  AND EXPIRY_TIMESTAMP < ?
            """, (now,))
            rc = c.rowcount
            conn.commit()
            if rc > 0:
                logger.info(f"Auto-unlocked {rc} expired rule locks.")
        except Exception as ex:
            logger.error(f"Error auto-unlocking expired locks: {ex}")

    @staticmethod
    def rule_current_lock_owner(conn, rule_id):
        c = conn.cursor()
        c.execute("""
            SELECT LOCKED_BY, LOCK_TIMESTAMP, EXPIRY_TIMESTAMP, FORCE_LOCK
            FROM BRM_RULE_LOCKS
            WHERE RULE_ID=? AND ACTIVE_LOCK=1
        """, (rule_id,))
        row = c.fetchone()
        if not row:
            return None
        locked_by, lts, et, fflag = row
        now = datetime.now()
        if et and now > et:
            # Lock expired
            try:
                c2 = conn.cursor()
                c2.execute("UPDATE BRM_RULE_LOCKS SET ACTIVE_LOCK=0 WHERE RULE_ID=? AND ACTIVE_LOCK=1", (rule_id,))
                conn.commit()
            except Exception as ex:
                logger.error(f"Error expiring lock for rule {rule_id}: {ex}")
            return None
        return (locked_by, lts, et, fflag)

    @staticmethod
    def lock_rule_for_edit(conn, rule_id, user_id, force=False, lock_minutes=30):
        LockManager.auto_unlock_expired_locks(conn)
        info = LockManager.rule_current_lock_owner(conn, rule_id)
        now = datetime.now()
        expiry = now + timedelta(minutes=lock_minutes)
        c = conn.cursor()
        if info is not None:
            locked_by, old_ts, old_exp, fflag = info
            if locked_by == user_id:
                # Refresh existing lock
                c.execute("""
                    UPDATE BRM_RULE_LOCKS
                    SET LOCK_TIMESTAMP=?, EXPIRY_TIMESTAMP=?, FORCE_LOCK=?
                    WHERE RULE_ID=? AND ACTIVE_LOCK=1
                """, (now, expiry, 1 if force else 0, rule_id))
                conn.commit()
                logger.debug(f"Lock for rule {rule_id} refreshed by {user_id}. Force={force}")
                return
            else:
                if not force:
                    raise ValueError(f"Rule {rule_id} is locked by {locked_by}.")
                else:
                    # Force override
                    c.execute("UPDATE BRM_RULE_LOCKS SET ACTIVE_LOCK=0 WHERE RULE_ID=? AND ACTIVE_LOCK=1", (rule_id,))
                    c.execute("""
                        INSERT INTO BRM_RULE_LOCKS(
                          RULE_ID, LOCKED_BY, LOCK_TIMESTAMP, EXPIRY_TIMESTAMP,
                          FORCE_LOCK, ACTIVE_LOCK
                        )
                        VALUES(?,?,?,?,?,1)
                    """, (rule_id, user_id, now, expiry, 1))
                    conn.commit()
                    logger.debug(f"Rule {rule_id} forcibly re-locked by {user_id}.")
                    return
        else:
            # No active lock
            c.execute("""
                INSERT INTO BRM_RULE_LOCKS(
                  RULE_ID, LOCKED_BY, LOCK_TIMESTAMP, EXPIRY_TIMESTAMP,
                  FORCE_LOCK, ACTIVE_LOCK
                )
                VALUES(?,?,?,?,?,1)
            """, (rule_id, user_id, now, expiry, 1 if force else 0))
            conn.commit()
            logger.debug(f"Rule {rule_id} locked by {user_id}, force={force}.")

    @staticmethod
    def unlock_rule_for_edit(conn, rule_id, user_id, force=False):
        LockManager.auto_unlock_expired_locks(conn)
        info = LockManager.rule_current_lock_owner(conn, rule_id)
        if not info:
            return  # not locked or already expired
        locked_by, lts, et, fflag = info
        if locked_by != user_id and not force:
            raise ValueError(f"Rule {rule_id} is locked by {locked_by}, cannot unlock.")
        c = conn.cursor()
        c.execute("""
            UPDATE BRM_RULE_LOCKS
            SET ACTIVE_LOCK=0
            WHERE RULE_ID=? AND ACTIVE_LOCK=1
        """, (rule_id,))
        conn.commit()
        logger.debug(f"Rule {rule_id} unlocked by user {user_id}, force={force}.")
##############################################################################
# (6) ADVANCED SQL PARSER
##############################################################################

def detect_operation_type(sql_text: str) -> str:
    """
    Return one of: INSERT, UPDATE, DELETE, SELECT, or OTHER.
    Enhanced: Strips comments/whitespace before determining the operation type.
    """
    cleaned = re.sub(r'(--.*?$)|(/\*.*?\*/)', '', sql_text or '', flags=re.MULTILINE | re.DOTALL).lstrip()
    up = cleaned.upper()
    if up.startswith("INSERT"):
        return "INSERT"
    elif up.startswith("UPDATE"):
        return "UPDATE"
    elif up.startswith("DELETE"):
        return "DELETE"
    elif up.startswith("SELECT"):
        return "SELECT"
    else:
        return "OTHER"


def parse_sql_dependencies(sql_text: str):
    """
    Use sqlparse to identify table references, columns, CTE usage, etc.
    Returns a dict with keys 'tables', 'cte_tables', 'alias_map', 'columns'.
    Enhanced with more robust error handling for edge cases.
    """
    try:
        statements = sqlparse.parse(sql_text)
    except Exception as ex:
        logger.error(f"SQL parsing error: {ex}")
        return {"tables": [], "cte_tables": [], "alias_map": {}, "columns": []}

    all_tables = []
    cte_info = []
    alias_map = {}
    columns = []

    for stmt in statements:
        ctes = _extract_with_clauses(stmt)
        for cName, cRefs in ctes.items():
            cte_info.append((cName, cRefs))

        main_refs, main_alias = _extract_main_from(stmt.tokens, set(ctes.keys()))
        all_tables.extend(main_refs)
        alias_map.update(main_alias)

        col_refs = _extract_columns(stmt)
        columns.extend(col_refs)

    unique_tables = list({x[1] for x in all_tables if x[1] is not None})
    return {
        "tables": unique_tables,
        "cte_tables": cte_info,
        "alias_map": alias_map,
        "columns": columns
    }

# Helper functions for parse_sql_dependencies

def _extract_with_clauses(statement):
    tokens = list(statement.tokens)
    i = 0
    cte_map = {}
    from sqlparse.tokens import Keyword

    while i < len(tokens):
        tk = tokens[i]
        if tk.ttype is Keyword and tk.value.upper() == "WITH":
            i += 1
            i = _parse_cte_block(tokens, i, cte_map)
            continue
        i += 1
    return cte_map

def _parse_cte_block(tokens, i, cte_map):
    from sqlparse.sql import Identifier, Parenthesis
    from sqlparse.tokens import Keyword

    while i < len(tokens):
        tk = tokens[i]
        if isinstance(tk, Identifier):
            cte_name = tk.get_real_name()
            i += 1
            i = _parse_cte_as_clause(tokens, i, cte_name, cte_map)
        elif tk.ttype is Keyword and tk.value.upper() in ("SELECT", "INSERT", "UPDATE", "DELETE"):
            return i
        else:
            i += 1
    return i

def _parse_cte_as_clause(tokens, i, cte_name, cte_map):
    from sqlparse.sql import Parenthesis
    while i < len(tokens):
        tk = tokens[i]
        if tk.value.upper() == "AS":
            i += 1
            if i < len(tokens):
                sub = tokens[i]
                if isinstance(sub, Parenthesis):
                    sub_refs = _extract_subselect_tokens(sub.tokens)
                    cte_map[cte_name] = sub_refs
                    i += 1
                    return i
        else:
            i += 1
    return i

def _extract_subselect_tokens(tokens):
    from sqlparse.sql import IdentifierList, Identifier
    from sqlparse.tokens import Keyword
    results = []
    from_seen = False
    i = 0
    while i < len(tokens):
        tk = tokens[i]
        if hasattr(tk, "is_group") and tk.is_group and _is_subselect(tk):
            results.extend(_extract_subselect_tokens(tk.tokens))
        if tk.ttype is Keyword:
            upv = tk.value.upper()
            if upv in ("FROM", "JOIN", "INNER JOIN", "LEFT JOIN", "RIGHT JOIN", "FULL JOIN"):
                from_seen = True
            else:
                from_seen = False
        if from_seen:
            if isinstance(tk, IdentifierList):
                for ident in tk.get_identifiers():
                    st = _parse_identifier(ident, set())
                    results.append(st)
            elif isinstance(tk, Identifier):
                st = _parse_identifier(tk, set())
                results.append(st)
        i += 1
    return results

def _is_subselect(token):
    from sqlparse.tokens import DML
    if not token.is_group:
        return False
    for sub in token.tokens:
        if sub.ttype is DML and sub.value.upper() == "SELECT":
            return True
    return False

def _extract_main_from(tokenlist, known_cte_names):
    from sqlparse.tokens import Keyword
    from sqlparse.sql import IdentifierList, Identifier
    results = []
    alias_map = {}
    tokens = list(tokenlist)
    from_seen = False
    i = 0
    while i < len(tokens):
        tk = tokens[i]
        if hasattr(tk, "is_group") and tk.is_group and _is_subselect(tk):
            results.extend(_extract_subselect_tokens(tk.tokens))
        if tk.ttype is Keyword:
            upv = tk.value.upper()
            if upv in ("FROM", "JOIN", "INNER JOIN", "LEFT JOIN", "RIGHT JOIN", "FULL JOIN"):
                from_seen = True
            else:
                from_seen = False
        if from_seen:
            if isinstance(tk, IdentifierList):
                for ident in tk.get_identifiers():
                    st = _parse_identifier(ident, known_cte_names)
                    results.append(st)
                    if st[2]:
                        alias_map[st[2]] = (st[0], st[1])
            elif isinstance(tk, Identifier):
                st = _parse_identifier(tk, known_cte_names)
                results.append(st)
                if st[2]:
                    alias_map[st[2]] = (st[0], st[1])
        i += 1
    return (results, alias_map)

def _parse_identifier(ident, known_cte_names):
    alias = ident.get_alias()
    real_name = ident.get_real_name()
    schema = ident.get_parent_name()
    if real_name and real_name.upper() in (n.upper() for n in known_cte_names):
        return (None, f"(CTE) {real_name}", alias, False)
    return (schema, real_name, alias, False)

def _extract_columns(statement):
    from sqlparse.tokens import DML, Keyword
    from sqlparse.sql import IdentifierList, Identifier, Parenthesis
    results = []
    tokens = list(statement.tokens)
    i = 0
    while i < len(tokens):
        tk = tokens[i]
        if tk.ttype is DML:
            upv = tk.value.upper()
            if upv == "SELECT":
                results.extend(_parse_select_list(tokens, i + 1))
            elif upv in ("INSERT", "UPDATE"):
                results.extend(_parse_dml_columns(tokens, i, upv))
        i += 1
    return results

def _parse_select_list(tokens, start_idx):
    from sqlparse.tokens import Keyword
    from sqlparse.sql import IdentifierList, Identifier
    columns = []
    i = start_idx
    while i < len(tokens):
        tk = tokens[i]
        if tk.ttype is Keyword:
            upv = tk.value.upper()
            if upv in ("FROM", "JOIN", "WHERE", "GROUP", "ORDER", "UNION", "INTERSECT"):
                break
        if isinstance(tk, IdentifierList):
            for ident in tk.get_identifiers():
                nm = ident.get_name()
                if nm and nm.upper() not in ("DISTINCT", "TOP", "ALL"):
                    columns.append(nm)
        elif isinstance(tk, Identifier):
            nm = tk.get_name()
            if nm and nm.upper() not in ("DISTINCT", "TOP", "ALL"):
                columns.append(nm)
        i += 1
    return columns

def _parse_dml_columns(tokens, start_idx, dml_word):
    from sqlparse.tokens import Keyword
    from sqlparse.sql import Parenthesis, IdentifierList, Identifier
    columns = []
    if dml_word == "INSERT":
        i = start_idx
        while i < len(tokens):
            tk = tokens[i]
            if tk.is_group and isinstance(tk, Parenthesis):
                for sub in tk.tokens:
                    if isinstance(sub, IdentifierList):
                        for ident in sub.get_identifiers():
                            columns.append(ident.get_name())
                    elif isinstance(sub, Identifier):
                        columns.append(sub.get_name())
                return columns
            i += 1
    elif dml_word == "UPDATE":
        found_set = False
        i = start_idx
        while i < len(tokens):
            tk = tokens[i]
            if tk.ttype is Keyword and tk.value.upper() == "SET":
                found_set = True
                i += 1
                columns.extend(_parse_update_set_list(tokens, i))
                break
            i += 1
    return columns

def _parse_update_set_list(tokens, start_i):
    from sqlparse.tokens import Keyword
    from sqlparse.sql import Identifier
    cols = []
    i = start_i
    while i < len(tokens):
        tk = tokens[i]
        if tk.ttype is Keyword and tk.value.upper() in ("WHERE", "FROM"):
            break
        if isinstance(tk, Identifier):
            cols.append(tk.get_name())
        i += 1
    return cols

##############################################################################
# (7) LOGIN DIALOG (PLAIN TEXT PASSWORD COMPARISON)
##############################################################################

class LoginDialog(QtWidgets.QDialog):
    """
    Minimal user/password dialog that checks the USERS table.
    Uses plain-text password comparison, as requested.
    Enhanced with potential RBAC logic placeholders.
    """
    def __init__(self, connection, parent=None):
        super().__init__(parent)
        self.connection = connection
        self.user_id = None
        self.user_group = None

        self.setWindowTitle("Login – Enhanced")
        self.resize(300, 150)

        main_layout = QVBoxLayout(self)
        self.user_edit = QLineEdit()
        self.user_edit.setPlaceholderText("Username")
        main_layout.addWidget(QLabel("Username:"))
        main_layout.addWidget(self.user_edit)

        self.pass_edit = QLineEdit()
        self.pass_edit.setPlaceholderText("Password")
        self.pass_edit.setEchoMode(QLineEdit.Password)
        main_layout.addWidget(QLabel("Password:"))
        main_layout.addWidget(self.pass_edit)

        login_btn = QPushButton("Login")
        login_btn.clicked.connect(self.do_login)
        main_layout.addWidget(login_btn)

        self.setLayout(main_layout)

    def do_login(self):
        un = self.user_edit.text().strip()
        pw = self.pass_edit.text().strip()

        if not un or not pw:
            QMessageBox.warning(self, "Error", "Both username and password are required.")
            return

        try:
            logger.debug(f"Attempting login for user: {un}")
            c = self.connection.cursor()
            c.execute("""
                SELECT USER_ID, USER_GROUP 
                FROM USERS
                WHERE USERNAME = ? AND PASSWORD = ?
            """, (un, pw))
            row = c.fetchone()
            if row:
                self.user_id = row[0]
                self.user_group = row[1]
                logger.info(f"User {un} logged in successfully. user_id={self.user_id}, user_group={self.user_group}")
                self.accept()
            else:
                logger.warning(f"Login failed for user: {un} - Invalid credentials.")
                QMessageBox.warning(self, "Login Failed", "Invalid credentials.")
        except Exception as ex:
            logger.exception("Error during login:")
            QMessageBox.critical(self, "Database Error", f"An error occurred during login:\n{ex}")

##############################################################################
# (8) ONBOARDING WIZARD (FULLY IMPLEMENTED)
##############################################################################

class OnboardingWizard(QDialog):
    """
    A multi-step wizard for brand-new users:
      Step 1) create a group
      Step 2) create a rule
      Step 3) schedule it
    Then done. Provides explicit guidance with no placeholders.
    Optionally extended with bubble tours / tooltips.
    """
    def __init__(self, connection, parent=None):
        super().__init__(parent)
        self.connection = connection
        self.current_step = 0
        self.setWindowTitle("Onboarding Wizard – Enhanced")
        self.resize(400, 250)
        main_l = QVBoxLayout(self)

        self.label = QLabel("Welcome to the BRM Tool! This wizard helps new users complete initial setup.")
        main_l.addWidget(self.label)

        self.next_btn = QPushButton("Next")
        self.next_btn.clicked.connect(self.advance_step)
        main_l.addWidget(self.next_btn)

        self.setLayout(main_l)

    def advance_step(self):
        self.current_step += 1
        if self.current_step == 1:
            self.label.setText("Step 1: Navigate to 'Group Management' to create a new group.\n"
                               "For example, name it after your department or risk domain.")
        elif self.current_step == 2:
            self.label.setText("Step 2: Navigate to 'Business Rules' to add a new rule.\n"
                               "For instance, create a basic threshold check rule.")
        elif self.current_step == 3:
            self.label.setText("Step 3: Navigate to 'Scheduling' to schedule your new rule to run automatically.")
        else:
            self.label.setText("Setup complete! Enjoy using the BRM Tool.")
            self.accept()

##############################################################################
# (9) sync_metadata_improved
##############################################################################

def sync_metadata_improved(conn):
    """
    Marks missing table references in BRM_RULE_TABLE_DEPENDENCIES by prefixing 'MISSING_'.
    Provides comprehensive error handling and logging.
    """
    try:
        c = conn.cursor()
        c.execute("""
            SELECT s.name AS schema_name, t.name AS table_name
            FROM sys.tables t
            JOIN sys.schemas s ON t.schema_id=s.schema_id
            ORDER BY s.name, t.name
        """)
        actual_tables = set()
        for row in c.fetchall():
            full_n = (f"{row[0]}.{row[1]}").lower()
            actual_tables.add(full_n)

        c.execute("SELECT DEPENDENCY_ID, DATABASE_NAME, TABLE_NAME FROM BRM_RULE_TABLE_DEPENDENCIES")
        deps = c.fetchall()
        missing_count = 0
        for (dep_id, dbn, tbl) in deps:
            if not tbl:
                continue
            low_tbl = tbl.lower().strip()
            if "." not in low_tbl:
                low_tbl = f"dbo.{low_tbl}"
            if low_tbl not in actual_tables:
                c2 = conn.cursor()
                c2.execute("""
                    UPDATE BRM_RULE_TABLE_DEPENDENCIES
                    SET TABLE_NAME='MISSING_' + TABLE_NAME
                    WHERE DEPENDENCY_ID=?
                """, (dep_id,))
                missing_count += 1

        conn.commit()
        msg = (f"Metadata sync complete. Found {len(actual_tables)} real DB tables.\n"
               f"Scanned {len(deps)} dependencies.\n"
               f"Marked {missing_count} references as 'MISSING_'.")
        logger.info(msg)
        return msg
    except Exception as ex:
        logger.error(f"Sync metadata error: {ex}")
        return f"Sync error: {ex}"
