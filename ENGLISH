import sqlparse
from sqlparse.tokens import Keyword, DML, Name, Whitespace, Punctuation

###############################################################################
# 1) DOMAIN MAP
###############################################################################
# Replace these entries with real table/column names in your environment.
DOMAIN_MAP = {
    "tables": {
        "financial_risk_table": "the Financial Risk data store",
        "customer_info": "the Customer Information table"
    },
    "columns": {
        "customer_id": "Customer Identifier",
        "exposure_amount": "Exposure Amount (USD)",
        "rating": "Credit Rating",
        "cusip_id": "CUSIP Identifier",
        "customer_name": "Customer Name",
        "total_exposure": "Total Exposure (USD)"
    }
}

def get_domain_table_name(raw_name: str) -> str:
    """Look up a table name in the domain map, or return as-is if not found."""
    key = raw_name.lower().strip()
    return DOMAIN_MAP["tables"].get(key, raw_name)

def get_domain_column_name(raw_name: str) -> str:
    """Look up a column name in the domain map, or return as-is if not found."""
    key = raw_name.lower().strip()
    return DOMAIN_MAP["columns"].get(key, raw_name)


###############################################################################
# 2) TOKEN-BASED PARSING LOGIC
###############################################################################
def parse_sql_statement(sql_query: str) -> dict:
    """
    Uses sqlparse to tokenize the query. We'll do naive scanning for:
    SELECT columns, FROM table, WHERE condition, GROUP BY, ORDER BY, LIMIT.
    
    Returns a dictionary with keys:
      {
        "columns": [...],
        "table": ...,
        "where": ...,
        "group_by": [...],
        "order_by": [...],
        "limit": ...
      }
    This approach is simplified and may not handle all edge cases.
    """
    result = {
        "columns": [],
        "table": None,
        "where": None,
        "group_by": [],
        "order_by": [],
        "limit": None
    }

    # 1) Parse using sqlparse
    parsed = sqlparse.parse(sql_query)
    if not parsed:
        return result  # empty or invalid
    statement = parsed[0]  # We'll assume only one statement
    
    # Flatten tokens for easier scanning
    tokens = [t for t in statement.tokens if not t.is_whitespace]

    # We'll track which "clause" we're in
    mode = None

    # A helper function to handle comma-separated items
    def split_by_comma(token_list):
        # E.g. "customer_id, SUM(exposure_amount) AS total_exposure"
        # We'll just re-split on commas (very naive).
        combined = "".join(t.value for t in token_list).strip()
        parts = [p.strip() for p in combined.split(",")]
        return parts

    # We'll accumulate tokens for the current clause
    buffer = []

    i = 0
    n = len(tokens)
    while i < n:
        token = tokens[i]
        ttype = token.ttype
        tval = token.value.upper()

        if token.is_keyword or ttype == DML:
            # Identify clauses by keywords
            if tval == "SELECT":
                # Finish any previous buffer
                if buffer:
                    buffer = []
                mode = "SELECT"
            elif tval == "FROM":
                # If we have leftover in buffer, let's parse them as columns
                if mode == "SELECT" and buffer:
                    cols = split_by_comma(buffer)
                    result["columns"].extend(cols)
                buffer = []
                mode = "FROM"
            elif tval == "WHERE":
                # finalize FROM
                if mode == "FROM" and buffer:
                    # The last token in buffer might be table name/alias
                    table_name = "".join(t.value for t in buffer).strip()
                    result["table"] = table_name
                # finalize SELECT if somehow not done
                if mode == "SELECT" and buffer:
                    cols = split_by_comma(buffer)
                    result["columns"].extend(cols)
                buffer = []
                mode = "WHERE"
            elif tval == "GROUP" and i + 1 < n and tokens[i+1].value.upper() == "BY":
                # finalize FROM or WHERE
                if mode == "FROM" and buffer:
                    result["table"] = "".join(t.value for t in buffer).strip()
                if mode == "WHERE" and buffer:
                    result["where"] = "".join(t.value for t in buffer).strip()
                # skip the "BY" token
                i += 1
                buffer = []
                mode = "GROUP BY"
            elif tval == "ORDER" and i + 1 < n and tokens[i+1].value.upper() == "BY":
                # finalize previous mode
                if mode == "FROM" and buffer:
                    result["table"] = "".join(t.value for t in buffer).strip()
                if mode == "WHERE" and buffer:
                    result["where"] = "".join(t.value for t in buffer).strip()
                if mode == "GROUP BY" and buffer:
                    group_cols = split_by_comma(buffer)
                    result["group_by"].extend(group_cols)
                # skip the "BY" token
                i += 1
                buffer = []
                mode = "ORDER BY"
            elif tval == "LIMIT":
                # finalize previous clause
                if mode == "FROM" and buffer:
                    result["table"] = "".join(t.value for t in buffer).strip()
                if mode == "WHERE" and buffer:
                    result["where"] = "".join(t.value for t in buffer).strip()
                if mode == "GROUP BY" and buffer:
                    group_cols = split_by_comma(buffer)
                    result["group_by"].extend(group_cols)
                if mode == "ORDER BY" and buffer:
                    order_parts = split_by_comma(buffer)
                    result["order_by"].extend(order_parts)
                buffer = []
                mode = "LIMIT"
            else:
                # Some other keyword, e.g. "JOIN", "ON", "HAVING" etc.
                # We'll just add it to buffer
                buffer.append(token)
        else:
            # Not a significant keyword, add to current buffer
            buffer.append(token)

        i += 1

    # End of tokens, finalize last buffer
    if mode == "SELECT" and buffer:
        cols = split_by_comma(buffer)
        result["columns"].extend(cols)
    elif mode == "FROM" and buffer:
        table_name = "".join(t.value for t in buffer).strip()
        result["table"] = table_name
    elif mode == "WHERE" and buffer:
        result["where"] = "".join(t.value for t in buffer).strip()
    elif mode == "GROUP BY" and buffer:
        group_cols = split_by_comma(buffer)
        result["group_by"].extend(group_cols)
    elif mode == "ORDER BY" and buffer:
        order_parts = split_by_comma(buffer)
        result["order_by"].extend(order_parts)
    elif mode == "LIMIT" and buffer:
        limit_val = "".join(t.value for t in buffer).strip()
        result["limit"] = limit_val

    return result

###############################################################################
# 3) BUILD ENGLISH EXPLANATION
###############################################################################
def build_explanation(parsed_info: dict) -> str:
    """
    Takes the dictionary from parse_sql_statement(...) and
    produces a domain-aware English explanation.
    """
    # domain_map usage
    columns = parsed_info.get("columns", [])
    table = parsed_info.get("table")
    where = parsed_info.get("where")
    group_by = parsed_info.get("group_by", [])
    order_by = parsed_info.get("order_by", [])
    limit = parsed_info.get("limit")

    explanation_parts = []

    # Table
    if table:
        # Could contain alias or multiple tokens if naive. Let's assume the first token is the real table name
        # We'll do a quick parse for the first word
        table_name_raw = table.split()[0].strip()
        table_name = get_domain_table_name(table_name_raw)
        explanation_parts.append(f"This query retrieves data from {table_name}.")

    # Columns
    if columns:
        # We'll attempt to domain-map each column or expression
        mapped_cols = []
        for col in columns:
            # If it has AS, we skip to the left side or parse the alias
            # e.g. "SUM(exposure_amount) AS total_exposure"
            mapped_cols.append(domain_map_column_expression(col))
        joined_cols = ", ".join(mapped_cols)
        explanation_parts.append(f"It selects: {joined_cols}.")

    # WHERE
    if where:
        explanation_parts.append(f"It is filtered by {where}.")

    # GROUP BY
    if group_by:
        # domain-map each group expression
        mapped_g = [domain_map_column_expression(g) for g in group_by]
        explanation_parts.append("Results are grouped by " + ", ".join(mapped_g) + ".")

    # ORDER BY
    if order_by:
        # We might see e.g. ["total_exposure DESC"] or separate tokens. We'll keep it simple:
        mapped_o = [domain_map_column_expression(o.strip()) for o in order_by]
        explanation_parts.append("It is then sorted by " + ", ".join(mapped_o) + ".")

    # LIMIT
    if limit:
        explanation_parts.append(f"Finally, it returns only the first {limit} rows.")

    if not explanation_parts:
        return "No explanation found. The query might be empty or too complex for this simple parser."
    return " ".join(explanation_parts)

def domain_map_column_expression(expr: str) -> str:
    """
    Attempt to domain-map known columns in the expression.
    e.g. "SUM(exposure_amount) AS total_exposure" -> "SUM(Exposure Amount (USD)) AS total_exposure"
    """
    # Very naive approach: find tokens that might be columns
    # We'll look for a token that doesn't contain '(' or ')' or function, etc.
    # If we see "exposure_amount", we replace with "Exposure Amount (USD)"
    # If we see "financial_risk_table.customer_id", we'll map the right side
    # This is just a simplistic approach for demonstration.
    tokens = expr.replace(",", "").split()
    replaced = []
    for t in tokens:
        # Remove possible punctuation
        tt = t.strip("(),")
        # If it's uppercase function name like SUM, we skip domain map
        # If it's "AS", skip domain map
        if tt.upper() in ("SUM", "COUNT", "MIN", "MAX", "AVG", "AS", "DESC", "ASC"):
            replaced.append(t)
            continue

        if "." in tt:  
            # e.g. "table.column"
            parts = tt.split(".")
            if len(parts) == 2:
                col_mapped = get_domain_column_name(parts[1])
                replaced.append(t.replace(parts[1], col_mapped))
            else:
                replaced.append(t)
        else:
            # single token
            col_mapped = get_domain_column_name(tt)
            # keep original punctuation
            replaced.append(t.replace(tt, col_mapped))

    return " ".join(replaced)

###############################################################################
# 4) MAIN LOOP (STANDALONE CONSOLE APP)
###############################################################################
def main():
    print("Standalone SQL-to-English tool (using sqlparse).")
    print("Type or paste your SQL. Type 'exit' or 'quit' to stop.\n")

    while True:
        user_sql = input("SQL> ").strip()
        if user_sql.lower() in ("exit", "quit"):
            print("Goodbye!")
            break

        if not user_sql:
            continue

        parsed_dict = parse_sql_statement(user_sql)
        explanation = build_explanation(parsed_dict)
        print("\n--- EXPLANATION ---")
        print(explanation)
        print("-------------------\n")

if __name__ == "__main__":
    main()