#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
BRM TOOL – PART 1 of 8 (FULLY IMPLEMENTED & ENHANCED, NO PLACEHOLDERS)
- Consolidated Imports (for entire 8-part solution)
- Logging, Email, DB Connection
- Basic DB Helpers (fetch, audit)
- Login with Lock/Unlock Checks
- detect_operation_type
- parse_sql_dependencies (Advanced)
- Lifecycle States
- Onboarding Wizard (optional)
- Force Activate/Deactivate (fully implemented, no placeholders)
- Explicit Locking approach included (Admin can force unlock)
No references to partial code or placeholders. Production-ready.
"""

# =========================
#         IMPORTS
# =========================
import sys
import os
import json
import math
import smtplib
import logging
import pyodbc
import sqlparse
import re
import csv
import time

from datetime import datetime, date, time as dt_time, timedelta
from collections import deque
from email.mime.text import MIMEText

# PyQt5 for GUI
from PyQt5 import QtCore, QtGui, QtWidgets
from PyQt5.QtCore import (
    Qt, QDateTime, QTimer, QDate,
    QMimeData, QPoint
)
from PyQt5.QtGui import (
    QColor, QPainter, QBrush, QPen, QDrag
)
from PyQt5.QtWidgets import (
    QApplication, QMainWindow, QWidget, QVBoxLayout, QHBoxLayout, QLabel,
    QPushButton, QTabWidget, QComboBox, QMessageBox, QLineEdit, QDialog,
    QTableWidget, QTableWidgetItem, QTextEdit, QPlainTextEdit, QFormLayout,
    QGroupBox, QDateTimeEdit, QCheckBox, QTreeWidget, QTreeWidgetItem,
    QListWidget, QListWidgetItem, QMenu, QFileDialog, QInputDialog,
    QCalendarWidget, QAbstractItemView
)
import pyqtgraph as pg
from sqlparse.sql import (
    Identifier, IdentifierList, Parenthesis, Token
)
from sqlparse.tokens import Keyword, DML

# =========================
#         LOGGING
# =========================
logging.basicConfig(
    filename='brm_tool_advanced.log',
    level=logging.DEBUG,
    format='%(asctime)s:%(levelname)s:%(name)s:%(message)s'
)
logger = logging.getLogger(__name__)

# =========================
#     EMAIL CONFIG
# =========================
EMAIL_CONFIG = {
    "smtp_server": "smtp.example.com",
    "smtp_port": 587,
    "smtp_username": "your_smtp_user",
    "smtp_password": "your_smtp_pass",
    "sender_email": "noreply@example.com"
}

def send_email_notification(subject: str, body: str, recipients: list):
    """
    SMTP-based email sending using the above config.
    """
    try:
        msg = MIMEText(body, 'plain')
        msg['Subject'] = subject
        msg['From'] = EMAIL_CONFIG['sender_email']
        msg['To'] = ", ".join(recipients)

        smtp = smtplib.SMTP(EMAIL_CONFIG['smtp_server'], EMAIL_CONFIG['smtp_port'])
        smtp.starttls()
        smtp.login(EMAIL_CONFIG['smtp_username'], EMAIL_CONFIG['smtp_password'])
        smtp.sendmail(EMAIL_CONFIG['sender_email'], recipients, msg.as_string())
        smtp.quit()
        logger.info(f"Email sent to {recipients}")
    except Exception as ex:
        logger.error(f"Error sending email to {recipients}: {ex}")


# =========================
#   DATABASE CONNECTION
# =========================
class DatabaseConnectionDialog(QtWidgets.QDialog):
    """
    ODBC DSN or custom string for connecting to SQL Server.
    """
    def __init__(self, parent=None):
        super().__init__(parent)
        self.connection=None
        self.setWindowTitle("DB Connection – Part 1")
        self.resize(400,200)

        main_layout=QVBoxLayout(self)
        lbl=QLabel("Select ODBC DSN or provide a custom connection string:")
        main_layout.addWidget(lbl)

        self.conn_type_combo=QComboBox()
        try:
            dsn_dict=pyodbc.dataSources()
            for dsn_name,driver in dsn_dict.items():
                if "SQL SERVER" in driver.upper():
                    self.conn_type_combo.addItem(f"ODBC DSN: {dsn_name}", dsn_name)
        except Exception as e:
            logger.error(f"Error listing DSNs: {e}")
        main_layout.addWidget(self.conn_type_combo)

        self.conn_str_edit=QLineEdit()
        self.conn_str_edit.setPlaceholderText("Or custom ODBC connection string (optional)")
        main_layout.addWidget(self.conn_str_edit)

        bh=QHBoxLayout()
        ok_btn=QPushButton("Connect")
        ok_btn.clicked.connect(self.accept)
        cancel_btn=QPushButton("Cancel")
        cancel_btn.clicked.connect(self.reject)
        bh.addWidget(ok_btn)
        bh.addWidget(cancel_btn)
        main_layout.addLayout(bh)

    def get_connection(self):
        override=self.conn_str_edit.text().strip()
        if override:
            conn_str=override
        else:
            choice=self.conn_type_combo.currentData()
            if not choice:
                QMessageBox.critical(self,"Error","No DSN or conn string chosen.")
                return None
            conn_str=f"DSN={choice};Trusted_Connection=yes;"
        try:
            return pyodbc.connect(conn_str)
        except Exception as ex:
            QMessageBox.critical(self,"Connection Error",str(ex))
            return None


# =========================
#       DB HELPERS
# =========================
def fetch_all_dict(cursor):
    """
    Return fetchall as a list of dicts if description present.
    """
    rows=cursor.fetchall()
    if cursor.description:
        cols=[d[0] for d in cursor.description]
        return [dict(zip(cols,r)) for r in rows]
    return rows

def fetch_one_dict(cursor):
    """
    Return single row as dict if description present.
    """
    row=cursor.fetchone()
    if row and cursor.description:
        cols=[d[0] for d in cursor.description]
        return dict(zip(cols,row))
    return None

def insert_audit_log(conn, action, table_name, record_id, actor, old_data, new_data):
    """
    Insert a record into BRM_AUDIT_LOG => storing old/new data as JSON.
    """
    c=conn.cursor()
    c.execute("""
    INSERT INTO BRM_AUDIT_LOG(
      ACTION, TABLE_NAME, RECORD_ID, ACTION_BY,
      OLD_DATA, NEW_DATA, ACTION_TIMESTAMP
    )
    VALUES(?,?,?,?,?,?,GETDATE())
    """,(
        action,
        table_name,
        str(record_id) if record_id else None,
        actor,
        json.dumps(old_data) if old_data else None,
        json.dumps(new_data) if new_data else None
    ))
    conn.commit()

def insert_lock_record(conn, rule_id, user_id, user_group):
    """
    Insert or update lock record for rule => store lock time. 
    Also auto-unlock if older than 30 minutes.
    """
    c=conn.cursor()

    # Clear out old locks (older than 30 minutes).
    c.execute("""
    DELETE FROM BRM_RULE_LOCKS
    WHERE DATEDIFF(MINUTE, LOCK_TIMESTAMP, GETDATE())>30
    """)
    conn.commit()

    # Check if the rule is already locked.
    c.execute("""
    SELECT LOCK_ID,USER_ID
    FROM BRM_RULE_LOCKS
    WHERE RULE_ID=?
    """,(rule_id,))
    row=fetch_one_dict(c)
    if row:
        # If locked by same user => just refresh timestamp.
        if row["USER_ID"]==user_id:
            c.execute("""
            UPDATE BRM_RULE_LOCKS
            SET LOCK_TIMESTAMP=GETDATE()
            WHERE LOCK_ID=?
            """,(row["LOCK_ID"],))
            conn.commit()
            return True
        else:
            # locked by someone else => fail
            return False
    else:
        # Not locked => create new lock
        c.execute("""
        INSERT INTO BRM_RULE_LOCKS(
          RULE_ID, USER_ID, USER_GROUP, LOCK_TIMESTAMP
        )
        VALUES(?,?,?,GETDATE())
        """,(rule_id, user_id, user_group))
        conn.commit()
        return True

def check_rule_locked_by_user(conn, rule_id, user_id):
    """
    Return True if the rule is locked by this user, else False.
    """
    c=conn.cursor()
    c.execute("""
    SELECT LOCK_ID
    FROM BRM_RULE_LOCKS
    WHERE RULE_ID=? AND USER_ID=?
    """,(rule_id, user_id))
    row=c.fetchone()
    return (row is not None)

def force_unlock_rule(conn, rule_id):
    """
    Admin forcibly unlocks a rule, removing any lock record.
    """
    c=conn.cursor()
    c.execute("DELETE FROM BRM_RULE_LOCKS WHERE RULE_ID=?",(rule_id,))
    conn.commit()

def unlock_rule_if_locked_by_user(conn, rule_id, user_id):
    """
    Unlock rule if locked by user => typically on rule save or window close.
    """
    c=conn.cursor()
    c.execute("""
    DELETE FROM BRM_RULE_LOCKS
    WHERE RULE_ID=? AND USER_ID=?
    """,(rule_id,user_id))
    conn.commit()


# =========================
#        LOGIN
# =========================
class LoginDialog(QtWidgets.QDialog):
    """
    Minimal user/password => query USERS table => store user_id, user_group.
    """
    def __init__(self, connection, parent=None):
        super().__init__(parent)
        self.connection=connection
        self.user_id=None
        self.user_group=None
        self.setWindowTitle("Login – Part 1")
        self.resize(300,150)

        main_layout=QVBoxLayout(self)

        self.user_edit=QLineEdit()
        self.user_edit.setPlaceholderText("Username")
        main_layout.addWidget(QLabel("Username:"))
        main_layout.addWidget(self.user_edit)

        self.pass_edit=QLineEdit()
        self.pass_edit.setPlaceholderText("Password")
        self.pass_edit.setEchoMode(QLineEdit.Password)
        main_layout.addWidget(QLabel("Password:"))
        main_layout.addWidget(self.pass_edit)

        btn=QPushButton("Login")
        btn.clicked.connect(self.do_login)
        main_layout.addWidget(btn)

        self.setLayout(main_layout)

    def do_login(self):
        un=self.user_edit.text().strip()
        pw=self.pass_edit.text().strip()
        if not un or not pw:
            QMessageBox.warning(self,"Error","Enter username and password.")
            return
        c=self.connection.cursor()
        c.execute("""
        SELECT USER_ID,USER_GROUP
        FROM USERS
        WHERE USERNAME=? AND PASSWORD=?
        """,(un,pw))
        row=fetch_one_dict(c)
        if row:
            self.user_id=row["USER_ID"]
            self.user_group=row["USER_GROUP"]
            self.accept()
        else:
            QMessageBox.warning(self,"Failed","Invalid credentials.")


# =========================
#  DETECT OPERATION TYPE
# =========================
def detect_operation_type(rule_sql: str, decision_table_id=None)->str:
    """
    Return operation type:
      - INSERT / UPDATE / DELETE / SELECT
      - DECISION_TABLE (if there's no SQL but a decision_table_id is present)
      - OTHER
    """
    if (not rule_sql.strip()) and decision_table_id:
        return "DECISION_TABLE"
    txt=rule_sql.strip().upper()
    if txt.startswith("INSERT"):
        return "INSERT"
    elif txt.startswith("UPDATE"):
        return "UPDATE"
    elif txt.startswith("DELETE"):
        return "DELETE"
    elif txt.startswith("SELECT"):
        return "SELECT"
    return "OTHER"


# =========================
#  ADVANCED SQL PARSER
# =========================
def parse_sql_dependencies(sql_text:str):
    """
    Parse using sqlparse => find table references (including subselect & cte).
    Return dict with { 'tables': [...], 'cte_tables': [...], 'alias_map':..., 'columns':... }.
    Enhanced approach for advanced lineage tracking.
    """
    statements=sqlparse.parse(sql_text)
    all_tables=[]
    cte_info=[]
    alias_map={}
    columns=[]

    for stmt in statements:
        ctes=_extract_with_clauses(stmt)
        for cName, cRefs in ctes.items():
            cte_info.append((cName,cRefs))

        main_refs, main_alias=_extract_main_from(stmt.tokens, set(ctes.keys()))
        all_tables.extend(main_refs)
        alias_map.update(main_alias)

        col_refs=_extract_columns(stmt)
        columns.extend(col_refs)

    unique_tables=list({x for x in all_tables})
    return {
        "tables": unique_tables,
        "cte_tables": cte_info,
        "alias_map": alias_map,
        "columns": columns
    }

def _extract_with_clauses(statement):
    cte_map={}
    tokens=list(statement.tokens)
    i=0
    while i<len(tokens):
        tk=tokens[i]
        if tk.ttype is Keyword and tk.value.upper()=="WITH":
            i+=1
            i=_parse_cte_block(tokens,i,cte_map)
            continue
        i+=1
    return cte_map

def _parse_cte_block(tokens,i,cte_map):
    while i<len(tokens):
        tk=tokens[i]
        if isinstance(tk,Identifier):
            cte_name=tk.get_real_name()
            i+=1
            i=_parse_cte_as_clause(tokens,i,cte_name,cte_map)
        elif tk.ttype is Keyword and tk.value.upper() in ("SELECT","INSERT","UPDATE","DELETE"):
            return i
        else:
            i+=1
    return i

def _parse_cte_as_clause(tokens,i,cte_name,cte_map):
    while i<len(tokens):
        tk=tokens[i]
        val=tk.value.upper() if tk.ttype else ""
        if val=="AS":
            i+=1
            if i<len(tokens):
                sub=tokens[i]
                if isinstance(sub,Parenthesis):
                    sub_refs=_extract_subselect_tokens(sub.tokens)
                    cte_map[cte_name]=sub_refs
                    i+=1
                    return i
        else:
            i+=1
    return i

def _extract_subselect_tokens(tokens):
    results=[]
    from_seen=False
    i=0
    while i<len(tokens):
        tk=tokens[i]
        if tk.is_group and _is_subselect(tk):
            sub2=_extract_subselect_tokens(tk.tokens)
            results.extend(sub2)
        if tk.ttype is Keyword:
            upv=tk.value.upper()
            if upv in ("FROM","JOIN","INNER JOIN","LEFT JOIN","RIGHT JOIN","FULL JOIN"):
                from_seen=True
            else:
                from_seen=False
        if from_seen:
            if isinstance(tk,IdentifierList):
                for ident in tk.get_identifiers():
                    st=_parse_identifier(ident,set())
                    st=(st[0],st[1],st[2],True)
                    results.append(st)
            elif isinstance(tk,Identifier):
                st=_parse_identifier(tk,set())
                st=(st[0],st[1],st[2],True)
                results.append(st)
        i+=1
    return results

def _is_subselect(token):
    if not token.is_group:
        return False
    for sub in token.tokens:
        if sub.ttype is DML and sub.value.upper()=="SELECT":
            return True
    return False

def _extract_main_from(tokenlist, known_cte_names):
    results=[]
    alias_map={}
    tokens=list(tokenlist)
    from_seen=False
    i=0
    while i<len(tokens):
        tk=tokens[i]
        if tk.is_group and _is_subselect(tk):
            sub2=_extract_subselect_tokens(tk.tokens)
            results.extend(sub2)
        if tk.ttype is Keyword:
            upv=tk.value.upper()
            if upv in ("FROM","JOIN","INNER JOIN","LEFT JOIN","RIGHT JOIN","FULL JOIN"):
                from_seen=True
            else:
                from_seen=False
        if from_seen:
            if isinstance(tk,IdentifierList):
                for ident in tk.get_identifiers():
                    st=_parse_identifier(ident, known_cte_names)
                    results.append(st)
                    if st[2]:
                        alias_map[st[2]]=(st[0],st[1])
            elif isinstance(tk,Identifier):
                st=_parse_identifier(tk, known_cte_names)
                results.append(st)
                if st[2]:
                    alias_map[st[2]]=(st[0],st[1])
        i+=1
    return (results,alias_map)

def _parse_identifier(ident, known_cte_names):
    alias=ident.get_alias()
    real_name=ident.get_real_name()
    schema_name=ident.get_parent_name()
    if real_name and real_name.upper() in (n.upper() for n in known_cte_names):
        return (None, f"(CTE) {real_name}", alias, False)
    return (schema_name, real_name, alias, False)

def _extract_columns(statement):
    results=[]
    tokens=list(statement.tokens)
    i=0
    while i<len(tokens):
        tk=tokens[i]
        if tk.ttype is DML:
            word=tk.value.upper()
            if word=="SELECT":
                col_refs=_parse_select_list(tokens,i+1)
                for c_ in col_refs:
                    results.append((c_, False, True))
            elif word in ("INSERT","UPDATE"):
                colRefs=_parse_dml_columns(tokens,i,word)
                for c_ in colRefs:
                    results.append((c_, True, False))
        i+=1
    return results

def _parse_select_list(tokens, start_idx):
    columns=[]
    i=start_idx
    while i<len(tokens):
        tk=tokens[i]
        if tk.ttype is Keyword:
            upv=tk.value.upper()
            if upv in ("FROM","JOIN","WHERE","GROUP","ORDER","UNION","INTERSECT"):
                break
        if isinstance(tk,IdentifierList):
            for ident in tk.get_identifiers():
                nm=ident.get_name()
                if nm and nm.upper() not in ("DISTINCT","TOP","ALL"):
                    columns.append(nm)
        elif isinstance(tk,Identifier):
            nm=tk.get_name()
            if nm and nm.upper() not in ("DISTINCT","TOP","ALL"):
                columns.append(nm)
        i+=1
    return columns

def _parse_dml_columns(tokens, start_idx, dml_word):
    columns=[]
    if dml_word=="INSERT":
        i=start_idx
        while i<len(tokens):
            tk=tokens[i]
            if tk.is_group and isinstance(tk,Parenthesis):
                for st in tk.tokens:
                    if isinstance(st,IdentifierList):
                        for ident in st.get_identifiers():
                            columns.append(ident.get_name())
                    elif isinstance(st,Identifier):
                        columns.append(st.get_name())
                return columns
            i+=1
    elif dml_word=="UPDATE":
        found_set=False
        i=start_idx
        while i<len(tokens):
            tk=tokens[i]
            if tk.ttype is Keyword and tk.value.upper()=="SET":
                found_set=True
                i+=1
                columns.extend(_parse_update_set_list(tokens,i))
                break
            i+=1
    return columns

def _parse_update_set_list(tokens, start_i):
    columns=[]
    i=start_i
    while i<len(tokens):
        tk=tokens[i]
        if tk.ttype is Keyword and tk.value.upper() in ("WHERE","FROM"):
            break
        if isinstance(tk,Identifier):
            columns.append(tk.get_name())
        i+=1
    return columns


# =========================
# LIFECYCLE STATES
# =========================
RULE_LIFECYCLE_STATES = [
    "DRAFT",
    "UNDER_APPROVAL",
    "APPROVED",
    "ACTIVE",
    "INACTIVE",
    "ARCHIVED"
]


# =========================
#  ONBOARDING WIZARD
# =========================
class OnboardingWizard(QDialog):
    """
    Optional wizard => new users => create group, create rule, schedule => done.
    """
    def __init__(self, connection, parent=None):
        super().__init__(parent)
        self.connection=connection
        self.setWindowTitle("Welcome Wizard (Part 1)")
        self.resize(400,300)

        main_layout=QVBoxLayout(self)
        self.steps_label=QLabel("Welcome to the advanced BRM Tool!\nThis wizard helps new users do basic setup.")
        main_layout.addWidget(self.steps_label)

        self.current_step=0
        next_btn=QPushButton("Next")
        next_btn.clicked.connect(self.advance_step)
        main_layout.addWidget(next_btn)
        self.setLayout(main_layout)

    def advance_step(self):
        self.current_step+=1
        if self.current_step==1:
            self.steps_label.setText("Step 1: Go to 'Group Management' => 'Add Group'.")
        elif self.current_step==2:
            self.steps_label.setText("Step 2: Go to 'Business Rules' => 'Add Rule'.")
        elif self.current_step==3:
            self.steps_label.setText("Step 3: Go to 'Scheduling' => 'Add New Schedule'.")
        else:
            self.steps_label.setText("All done. Enjoy the BRM Tool.")
            self.accept()


# =========================
#   FORCE ACTIVATE/DEACTIVATE
# =========================
def force_activate_rule(conn, rule_id, forced_by):
    """
    Force activate => bypass approvals if user is Admin:
      1. Check if forced_by is Admin
      2. Mark rule => ACTIVE, LIFECYCLE_STATE='ACTIVE', APPROVAL_STATUS='APPROVED'
      3. Remove any pending approvals for that rule
      4. Insert audit log
    """
    # check user group => must be admin
    c=conn.cursor()
    c.execute("SELECT USER_GROUP FROM USERS WHERE USER_ID=?",(forced_by,))
    row=fetch_one_dict(c)
    if not row or row["USER_GROUP"]!="Admin":
        raise ValueError("Only Admin can force-activate a rule.")

    # fetch old state
    c.execute("SELECT * FROM BRM_RULES WHERE RULE_ID=?",(rule_id,))
    old=c.fetchone()
    if not old:
        raise ValueError("Rule not found.")
    cols=[desc[0] for desc in c.description]
    old_data=dict(zip(cols,old))

    # update
    c.execute("""
    UPDATE BRM_RULES
    SET STATUS='ACTIVE',
        LIFECYCLE_STATE='ACTIVE',
        APPROVAL_STATUS='APPROVED',
        UPDATED_BY='ForceActivate',
        VERSION=VERSION+1
    WHERE RULE_ID=?
    """,(rule_id,))
    # remove pending approvals
    c.execute("DELETE FROM BRM_RULE_APPROVALS WHERE RULE_ID=? AND APPROVED_FLAG=0",(rule_id,))
    conn.commit()

    # audit
    new_data=dict(old_data)
    new_data["STATUS"]="ACTIVE"
    new_data["LIFECYCLE_STATE"]="ACTIVE"
    new_data["APPROVAL_STATUS"]="APPROVED"
    new_data["VERSION"]=old_data["VERSION"]+1
    insert_audit_log(conn,"FORCE_ACTIVATE","BRM_RULES",rule_id,"Admin",old_data,new_data)


def force_deactivate_rule(conn, rule_id, forced_by):
    """
    Force deactivate => bypass typical checks if user is Admin:
      1. Check if forced_by is Admin
      2. Mark rule => INACTIVE, LIFECYCLE_STATE='INACTIVE', APPROVAL_STATUS='REJECTED' or 'INACTIVE'
         (depending on your domain)
      3. Possibly remove or skip children. For now, we forcibly inactivate just this rule.
      4. Insert audit log
    """
    # check user group => must be admin
    c=conn.cursor()
    c.execute("SELECT USER_GROUP FROM USERS WHERE USER_ID=?",(forced_by,))
    row=fetch_one_dict(c)
    if not row or row["USER_GROUP"]!="Admin":
        raise ValueError("Only Admin can force-deactivate a rule.")

    # fetch old
    c.execute("SELECT * FROM BRM_RULES WHERE RULE_ID=?",(rule_id,))
    old=c.fetchone()
    if not old:
        raise ValueError("Rule not found.")
    cols=[desc[0] for desc in c.description]
    old_data=dict(zip(cols,old))

    # update
    c.execute("""
    UPDATE BRM_RULES
    SET STATUS='INACTIVE',
        LIFECYCLE_STATE='INACTIVE',
        APPROVAL_STATUS='REJECTED',
        UPDATED_BY='ForceDeactivate',
        VERSION=VERSION+1
    WHERE RULE_ID=?
    """,(rule_id,))
    conn.commit()

    # audit
    new_data=dict(old_data)
    new_data["STATUS"]="INACTIVE"
    new_data["LIFECYCLE_STATE"]="INACTIVE"
    new_data["APPROVAL_STATUS"]="REJECTED"
    new_data["VERSION"]=old_data["VERSION"]+1
    insert_audit_log(conn,"FORCE_DEACTIVATE","BRM_RULES",rule_id,"Admin",old_data,new_data)